{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 64, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/ayush/Desktop/Main%20EL%203rd%20sem/cpcb-dashboard/src/lib/csv-reader.ts"],"sourcesContent":["// lib/csv-reader.ts\r\n// CSV-first data loader with auto-detection\r\n\r\nimport Papa from 'papaparse';\r\nimport fs from 'fs';\r\nimport path from 'path';\r\n\r\nexport interface CsvRow {\r\n    [key: string]: string | number;\r\n}\r\n\r\nexport interface CsvMetadata {\r\n    factories: string[];\r\n    numericColumns: string[];\r\n    violationRate: number;\r\n    topViolators: Array<{ factory: string; rate: number }>;\r\n    thresholds: Record<string, number>;\r\n    totalRows: number;\r\n    dateRange: { start: string; end: string };\r\n    sensors: string[];\r\n}\r\n\r\n/**\r\n * Parse CSV file from public directory\r\n */\r\nexport async function parseCsvFile(filePath: string = '/public/data.csv'): Promise<CsvRow[]> {\r\n    const fullPath = path.join(process.cwd(), filePath);\r\n    const fileContent = fs.readFileSync(fullPath, 'utf-8');\r\n\r\n    return new Promise((resolve, reject) => {\r\n        Papa.parse(fileContent, {\r\n            header: true,\r\n            dynamicTyping: true,\r\n            skipEmptyLines: true,\r\n            complete: (results) => {\r\n                resolve(results.data as CsvRow[]);\r\n            },\r\n            error: (error) => {\r\n                reject(error);\r\n            },\r\n        });\r\n    });\r\n}\r\n\r\n/**\r\n * Auto-detect numeric columns from CSV data\r\n */\r\nexport function getNumericColumns(data: CsvRow[]): string[] {\r\n    if (data.length === 0) return [];\r\n\r\n    const firstRow = data[0];\r\n    const numericCols: string[] = [];\r\n\r\n    for (const [key, value] of Object.entries(firstRow)) {\r\n        if (typeof value === 'number' && !key.includes('id') && !key.includes('baseline') && !key.includes('violation')) {\r\n            numericCols.push(key);\r\n        }\r\n    }\r\n\r\n    return numericCols;\r\n}\r\n\r\n/**\r\n * Extract unique factories from CSV\r\n */\r\nexport function getFactories(data: CsvRow[]): string[] {\r\n    const factories = new Set<string>();\r\n\r\n    data.forEach(row => {\r\n        if (row.factory_id && row.factory_id !== '') {\r\n            factories.add(row.factory_id as string);\r\n        }\r\n    });\r\n\r\n    return Array.from(factories).sort();\r\n}\r\n\r\n/**\r\n * Calculate violation rate per factory\r\n */\r\nexport function getViolationRates(data: CsvRow[]): Array<{ factory: string; rate: number; count: number }> {\r\n    const factoryStats: Record<string, { total: number; violations: number }> = {};\r\n\r\n    data.forEach(row => {\r\n        if (row.factory_id && row.factory_id !== '') {\r\n            const factory = row.factory_id as string;\r\n\r\n            if (!factoryStats[factory]) {\r\n                factoryStats[factory] = { total: 0, violations: 0 };\r\n            }\r\n\r\n            factoryStats[factory].total++;\r\n            if (row.is_violation === 1) {\r\n                factoryStats[factory].violations++;\r\n            }\r\n        }\r\n    });\r\n\r\n    return Object.entries(factoryStats)\r\n        .map(([factory, stats]) => ({\r\n            factory,\r\n            rate: stats.violations / stats.total,\r\n            count: stats.violations,\r\n        }))\r\n        .sort((a, b) => b.rate - a.rate);\r\n}\r\n\r\n/**\r\n * Extract thresholds from violation patterns\r\n */\r\nexport function extractThresholds(data: CsvRow[]): Record<string, number> {\r\n    const thresholds: Record<string, number> = {\r\n        turbidity_ntu: 200,\r\n        ph_low: 5.5,\r\n        ph_high: 9.0,\r\n        chromium_mg_l: 0.1,\r\n        copper_mg_l: 3.0,\r\n        tds_mg_l: 2100,\r\n        uv_vis_absorbance: 1.0,\r\n    };\r\n\r\n    // Could be enhanced to auto-detect from violation_reason patterns\r\n    return thresholds;\r\n}\r\n\r\n/**\r\n * Get complete CSV metadata\r\n */\r\nexport async function getCsvMetadata(): Promise<CsvMetadata> {\r\n    const data = await parseCsvFile();\r\n\r\n    const factories = getFactories(data);\r\n    const numericColumns = getNumericColumns(data);\r\n    const violationRates = getViolationRates(data);\r\n    const thresholds = extractThresholds(data);\r\n\r\n    const totalViolations = data.filter(row => row.is_violation === 1).length;\r\n    const violationRate = totalViolations / data.length;\r\n\r\n    // Get date range\r\n    const timestamps = data\r\n        .filter(row => row.timestamp)\r\n        .map(row => new Date(row.timestamp as string));\r\n\r\n    const dateRange = {\r\n        start: timestamps.length > 0 ? new Date(Math.min(...timestamps.map(d => d.getTime()))).toISOString() : '',\r\n        end: timestamps.length > 0 ? new Date(Math.max(...timestamps.map(d => d.getTime()))).toISOString() : '',\r\n    };\r\n\r\n    // Sensor columns (exclude metadata columns)\r\n    const excludeColumns = ['timestamp', 'reading_id', 'factory_id', 'factory_type', 'baseline_segment_id',\r\n        'is_baseline', 'is_violation', 'violation_reason', 'ai_violation_score',\r\n        'assigned_employee_id', 'alert_status'];\r\n    const sensors = numericColumns.filter(col => !excludeColumns.includes(col));\r\n\r\n    return {\r\n        factories,\r\n        numericColumns,\r\n        violationRate,\r\n        topViolators: violationRates.slice(0, 5),\r\n        thresholds,\r\n        totalRows: data.length,\r\n        dateRange,\r\n        sensors,\r\n    };\r\n}\r\n\r\n/**\r\n * Get min/max values for a column\r\n */\r\nexport function getColumnRange(data: CsvRow[], column: string): { min: number; max: number } {\r\n    const values = data\r\n        .map(row => row[column])\r\n        .filter(val => typeof val === 'number') as number[];\r\n\r\n    return {\r\n        min: Math.min(...values),\r\n        max: Math.max(...values),\r\n    };\r\n}\r\n\r\n/**\r\n * Filter data by factory\r\n */\r\nexport function filterByFactory(data: CsvRow[], factoryId: string): CsvRow[] {\r\n    return data.filter(row => row.factory_id === factoryId);\r\n}\r\n\r\n/**\r\n * Get recent readings (last N)\r\n */\r\nexport function getRecentReadings(data: CsvRow[], count: number = 100): CsvRow[] {\r\n    return data\r\n        .sort((a, b) => {\r\n            const dateA = new Date(a.timestamp as string).getTime();\r\n            const dateB = new Date(b.timestamp as string).getTime();\r\n            return dateB - dateA;\r\n        })\r\n        .slice(0, count);\r\n}\r\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA,oBAAoB;AACpB,4CAA4C;AAE5C;AACA;AACA;;;;AAoBO,eAAe,aAAa,WAAmB,kBAAkB;IACpE,MAAM,WAAW,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI;IAC1C,MAAM,cAAc,wGAAE,CAAC,YAAY,CAAC,UAAU;IAE9C,OAAO,IAAI,QAAQ,CAAC,SAAS;QACzB,mJAAI,CAAC,KAAK,CAAC,aAAa;YACpB,QAAQ;YACR,eAAe;YACf,gBAAgB;YAChB,UAAU,CAAC;gBACP,QAAQ,QAAQ,IAAI;YACxB;YACA,OAAO,CAAC;gBACJ,OAAO;YACX;QACJ;IACJ;AACJ;AAKO,SAAS,kBAAkB,IAAc;IAC5C,IAAI,KAAK,MAAM,KAAK,GAAG,OAAO,EAAE;IAEhC,MAAM,WAAW,IAAI,CAAC,EAAE;IACxB,MAAM,cAAwB,EAAE;IAEhC,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,OAAO,OAAO,CAAC,UAAW;QACjD,IAAI,OAAO,UAAU,YAAY,CAAC,IAAI,QAAQ,CAAC,SAAS,CAAC,IAAI,QAAQ,CAAC,eAAe,CAAC,IAAI,QAAQ,CAAC,cAAc;YAC7G,YAAY,IAAI,CAAC;QACrB;IACJ;IAEA,OAAO;AACX;AAKO,SAAS,aAAa,IAAc;IACvC,MAAM,YAAY,IAAI;IAEtB,KAAK,OAAO,CAAC,CAAA;QACT,IAAI,IAAI,UAAU,IAAI,IAAI,UAAU,KAAK,IAAI;YACzC,UAAU,GAAG,CAAC,IAAI,UAAU;QAChC;IACJ;IAEA,OAAO,MAAM,IAAI,CAAC,WAAW,IAAI;AACrC;AAKO,SAAS,kBAAkB,IAAc;IAC5C,MAAM,eAAsE,CAAC;IAE7E,KAAK,OAAO,CAAC,CAAA;QACT,IAAI,IAAI,UAAU,IAAI,IAAI,UAAU,KAAK,IAAI;YACzC,MAAM,UAAU,IAAI,UAAU;YAE9B,IAAI,CAAC,YAAY,CAAC,QAAQ,EAAE;gBACxB,YAAY,CAAC,QAAQ,GAAG;oBAAE,OAAO;oBAAG,YAAY;gBAAE;YACtD;YAEA,YAAY,CAAC,QAAQ,CAAC,KAAK;YAC3B,IAAI,IAAI,YAAY,KAAK,GAAG;gBACxB,YAAY,CAAC,QAAQ,CAAC,UAAU;YACpC;QACJ;IACJ;IAEA,OAAO,OAAO,OAAO,CAAC,cACjB,GAAG,CAAC,CAAC,CAAC,SAAS,MAAM,GAAK,CAAC;YACxB;YACA,MAAM,MAAM,UAAU,GAAG,MAAM,KAAK;YACpC,OAAO,MAAM,UAAU;QAC3B,CAAC,GACA,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,IAAI,GAAG,EAAE,IAAI;AACvC;AAKO,SAAS,kBAAkB,IAAc;IAC5C,MAAM,aAAqC;QACvC,eAAe;QACf,QAAQ;QACR,SAAS;QACT,eAAe;QACf,aAAa;QACb,UAAU;QACV,mBAAmB;IACvB;IAEA,kEAAkE;IAClE,OAAO;AACX;AAKO,eAAe;IAClB,MAAM,OAAO,MAAM;IAEnB,MAAM,YAAY,aAAa;IAC/B,MAAM,iBAAiB,kBAAkB;IACzC,MAAM,iBAAiB,kBAAkB;IACzC,MAAM,aAAa,kBAAkB;IAErC,MAAM,kBAAkB,KAAK,MAAM,CAAC,CAAA,MAAO,IAAI,YAAY,KAAK,GAAG,MAAM;IACzE,MAAM,gBAAgB,kBAAkB,KAAK,MAAM;IAEnD,iBAAiB;IACjB,MAAM,aAAa,KACd,MAAM,CAAC,CAAA,MAAO,IAAI,SAAS,EAC3B,GAAG,CAAC,CAAA,MAAO,IAAI,KAAK,IAAI,SAAS;IAEtC,MAAM,YAAY;QACd,OAAO,WAAW,MAAM,GAAG,IAAI,IAAI,KAAK,KAAK,GAAG,IAAI,WAAW,GAAG,CAAC,CAAA,IAAK,EAAE,OAAO,MAAM,WAAW,KAAK;QACvG,KAAK,WAAW,MAAM,GAAG,IAAI,IAAI,KAAK,KAAK,GAAG,IAAI,WAAW,GAAG,CAAC,CAAA,IAAK,EAAE,OAAO,MAAM,WAAW,KAAK;IACzG;IAEA,4CAA4C;IAC5C,MAAM,iBAAiB;QAAC;QAAa;QAAc;QAAc;QAAgB;QAC7E;QAAe;QAAgB;QAAoB;QACnD;QAAwB;KAAe;IAC3C,MAAM,UAAU,eAAe,MAAM,CAAC,CAAA,MAAO,CAAC,eAAe,QAAQ,CAAC;IAEtE,OAAO;QACH;QACA;QACA;QACA,cAAc,eAAe,KAAK,CAAC,GAAG;QACtC;QACA,WAAW,KAAK,MAAM;QACtB;QACA;IACJ;AACJ;AAKO,SAAS,eAAe,IAAc,EAAE,MAAc;IACzD,MAAM,SAAS,KACV,GAAG,CAAC,CAAA,MAAO,GAAG,CAAC,OAAO,EACtB,MAAM,CAAC,CAAA,MAAO,OAAO,QAAQ;IAElC,OAAO;QACH,KAAK,KAAK,GAAG,IAAI;QACjB,KAAK,KAAK,GAAG,IAAI;IACrB;AACJ;AAKO,SAAS,gBAAgB,IAAc,EAAE,SAAiB;IAC7D,OAAO,KAAK,MAAM,CAAC,CAAA,MAAO,IAAI,UAAU,KAAK;AACjD;AAKO,SAAS,kBAAkB,IAAc,EAAE,QAAgB,GAAG;IACjE,OAAO,KACF,IAAI,CAAC,CAAC,GAAG;QACN,MAAM,QAAQ,IAAI,KAAK,EAAE,SAAS,EAAY,OAAO;QACrD,MAAM,QAAQ,IAAI,KAAK,EAAE,SAAS,EAAY,OAAO;QACrD,OAAO,QAAQ;IACnB,GACC,KAAK,CAAC,GAAG;AAClB"}},
    {"offset": {"line": 226, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/ayush/Desktop/Main%20EL%203rd%20sem/cpcb-dashboard/src/app/api/csv-info/route.ts"],"sourcesContent":["// app/api/csv-info/route.ts\r\n// Auto-detect CSV structure and metadata\r\n\r\nimport { NextResponse } from 'next/server';\r\nimport { getCsvMetadata, parseCsvFile } from '@/lib/csv-reader';\r\n\r\nexport async function GET() {\r\n    try {\r\n        const metadata = await getCsvMetadata();\r\n\r\n        return NextResponse.json({\r\n            success: true,\r\n            data: metadata,\r\n        });\r\n    } catch (error) {\r\n        console.error('CSV info error:', error);\r\n        return NextResponse.json(\r\n            { success: false, error: 'Failed to read CSV file' },\r\n            { status: 500 }\r\n        );\r\n    }\r\n}\r\n\r\n/**\r\n * Get filtered CSV data\r\n */\r\nexport async function POST(request: Request) {\r\n    try {\r\n        const body = await request.json();\r\n        const { factory_id, limit = 100 } = body;\r\n\r\n        let data = await parseCsvFile();\r\n\r\n        // Filter by factory if specified\r\n        if (factory_id) {\r\n            data = data.filter(row => row.factory_id === factory_id);\r\n        }\r\n\r\n        // Limit results\r\n        data = data.slice(0, limit);\r\n\r\n        return NextResponse.json({\r\n            success: true,\r\n            data,\r\n            count: data.length,\r\n        });\r\n    } catch (error) {\r\n        console.error('CSV data error:', error);\r\n        return NextResponse.json(\r\n            { success: false, error: 'Failed to fetch CSV data' },\r\n            { status: 500 }\r\n        );\r\n    }\r\n}\r\n"],"names":[],"mappings":";;;;;;AAAA,4BAA4B;AAC5B,yCAAyC;AAEzC;AACA;;;AAEO,eAAe;IAClB,IAAI;QACA,MAAM,WAAW,MAAM,IAAA,+IAAc;QAErC,OAAO,gJAAY,CAAC,IAAI,CAAC;YACrB,SAAS;YACT,MAAM;QACV;IACJ,EAAE,OAAO,OAAO;QACZ,QAAQ,KAAK,CAAC,mBAAmB;QACjC,OAAO,gJAAY,CAAC,IAAI,CACpB;YAAE,SAAS;YAAO,OAAO;QAA0B,GACnD;YAAE,QAAQ;QAAI;IAEtB;AACJ;AAKO,eAAe,KAAK,OAAgB;IACvC,IAAI;QACA,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,MAAM,EAAE,UAAU,EAAE,QAAQ,GAAG,EAAE,GAAG;QAEpC,IAAI,OAAO,MAAM,IAAA,6IAAY;QAE7B,iCAAiC;QACjC,IAAI,YAAY;YACZ,OAAO,KAAK,MAAM,CAAC,CAAA,MAAO,IAAI,UAAU,KAAK;QACjD;QAEA,gBAAgB;QAChB,OAAO,KAAK,KAAK,CAAC,GAAG;QAErB,OAAO,gJAAY,CAAC,IAAI,CAAC;YACrB,SAAS;YACT;YACA,OAAO,KAAK,MAAM;QACtB;IACJ,EAAE,OAAO,OAAO;QACZ,QAAQ,KAAK,CAAC,mBAAmB;QACjC,OAAO,gJAAY,CAAC,IAAI,CACpB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAEtB;AACJ"}}]
}